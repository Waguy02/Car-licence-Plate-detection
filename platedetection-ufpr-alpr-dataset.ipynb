{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f02e73",
   "metadata": {
    "papermill": {
     "duration": 0.015565,
     "end_time": "2022-05-29T20:56:07.535325",
     "exception": false,
     "start_time": "2022-05-29T20:56:07.519760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b3e2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:07.565719Z",
     "iopub.status.busy": "2022-05-29T20:56:07.565404Z",
     "iopub.status.idle": "2022-05-29T20:56:47.892709Z",
     "shell.execute_reply": "2022-05-29T20:56:47.891843Z"
    },
    "papermill": {
     "duration": 40.344843,
     "end_time": "2022-05-29T20:56:47.895075",
     "exception": false,
     "start_time": "2022-05-29T20:56:07.550232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (4.2.0)\r\n",
      "Building wheels for collected packages: efficientnet_pytorch\r\n",
      "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=f345b951eac1d73a3b0c07378678308a9a42b5bcadaaf27624181dfae7fa6532\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\r\n",
      "Successfully built efficientnet_pytorch\r\n",
      "Installing collected packages: efficientnet_pytorch\r\n",
      "Successfully installed efficientnet_pytorch-0.7.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.6.3)\r\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12)\r\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.4)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\r\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.1.0)\r\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.43.0)\r\n",
      "Collecting six~=1.15.0\r\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\r\n",
      "Collecting typing-extensions<3.11,>=3.7\r\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\r\n",
      "Collecting wrapt~=1.12.1\r\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\r\n",
      "Collecting absl-py~=0.10\r\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\r\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\r\n",
      "Collecting numpy~=1.19.2\r\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (5.0)\r\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.27.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.3)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.8.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.7)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.11.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.7.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.0)\r\n",
      "Building wheels for collected packages: wrapt\r\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=77059 sha256=c8ee35fd7600af8c9f059ba24d5de670f123276a938bf975a94fab9cf61d5459\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\r\n",
      "Successfully built wrapt\r\n",
      "Installing collected packages: wrapt, typing-extensions, six, numpy, absl-py\r\n",
      "  Attempting uninstall: wrapt\r\n",
      "    Found existing installation: wrapt 1.14.0\r\n",
      "    Uninstalling wrapt-1.14.0:\r\n",
      "      Successfully uninstalled wrapt-1.14.0\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.2.0\r\n",
      "    Uninstalling typing_extensions-4.2.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.2.0\r\n",
      "  Attempting uninstall: six\r\n",
      "    Found existing installation: six 1.16.0\r\n",
      "    Uninstalling six-1.16.0:\r\n",
      "      Successfully uninstalled six-1.16.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.21.6\r\n",
      "    Uninstalling numpy-1.21.6:\r\n",
      "      Successfully uninstalled numpy-1.21.6\r\n",
      "  Attempting uninstall: absl-py\r\n",
      "    Found existing installation: absl-py 1.0.0\r\n",
      "    Uninstalling absl-py-1.0.0:\r\n",
      "      Successfully uninstalled absl-py-1.0.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "dask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tfx-bsl 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\r\n",
      "tfx-bsl 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\r\n",
      "tensorflow-transform 1.7.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.7.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<2.9,>=1.15.5, but you have tensorflow 2.6.3 which is incompatible.\r\n",
      "tensorflow-serving-api 2.8.0 requires tensorflow<3,>=2.8.0, but you have tensorflow 2.6.3 which is incompatible.\r\n",
      "rich 12.4.1 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "pytorch-lightning 1.6.3 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "pytools 2022.1.7 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.2 which is incompatible.\r\n",
      "imageio 2.16.1 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "grpcio-status 1.44.0 requires grpcio>=1.44.0, but you have grpcio 1.43.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-cloud-storage<2.0.0dev,>=1.26.0, but you have google-cloud-storage 2.1.0 which is incompatible.\r\n",
      "gcsfs 2022.2.0 requires fsspec==2022.02.0, but you have fsspec 2022.3.0 which is incompatible.\r\n",
      "flax 0.4.2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\r\n",
      "featuretools 1.9.0 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\r\n",
      "dask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\r\n",
      "apache-beam 2.37.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\r\n",
      "apache-beam 2.37.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.4 which is incompatible.\r\n",
      "apache-beam 2.37.0 requires pyarrow<7.0.0,>=0.15.1, but you have pyarrow 7.0.0 which is incompatible.\r\n",
      "aioitertools 0.10.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\r\n",
      "aiobotocore 2.2.0 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.25.12 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed absl-py-0.15.0 numpy-1.19.5 six-1.15.0 typing-extensions-3.10.0.2 wrapt-1.12.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch\n",
    "!pip install tensorflow\n",
    "# !pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9639706c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:47.963700Z",
     "iopub.status.busy": "2022-05-29T20:56:47.963467Z",
     "iopub.status.idle": "2022-05-29T20:56:47.969597Z",
     "shell.execute_reply": "2022-05-29T20:56:47.968942Z"
    },
    "papermill": {
     "duration": 0.042204,
     "end_time": "2022-05-29T20:56:47.971331",
     "exception": false,
     "start_time": "2022-05-29T20:56:47.929127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ROOT_DIR=\"/kaggle/working\"\n",
    "DATASET_ROOT_DIR=\"/kaggle/input/ufpr-alpr/UFPR-ALPR dataset\"\n",
    "CLASS_PLATE=\"PLATE\"\n",
    "CLASSES =[CLASS_PLATE]+ [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "CLASSES_IDS = {c:i for i, c in enumerate(CLASSES)}\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "ALLOW_GPU=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8466d365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:48.037492Z",
     "iopub.status.busy": "2022-05-29T20:56:48.036955Z",
     "iopub.status.idle": "2022-05-29T20:56:48.044050Z",
     "shell.execute_reply": "2022-05-29T20:56:48.043356Z"
    },
    "papermill": {
     "duration": 0.04199,
     "end_time": "2022-05-29T20:56:48.045661",
     "exception": false,
     "start_time": "2022-05-29T20:56:48.003671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from time import strftime\n",
    "import sys\n",
    "import logging\n",
    "def setup_logger():\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    a_logger = logging.getLogger()\n",
    "    a_logger.setLevel(\"INFO\")\n",
    "    log_dir=os.path.join(ROOT_DIR,\"logs\",\"output_logs\")\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    output_file_handler = logging.FileHandler(os.path.join(log_dir,strftime(\"log_%d_%m_%Y_%H_%M.log\")))\n",
    "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "    stdout_handler.setFormatter(formatter)\n",
    "    a_logger.propagate=False\n",
    "    a_logger.addHandler(output_file_handler)\n",
    "    a_logger.addHandler(stdout_handler)\n",
    "setup_logger()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73052aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:48.112193Z",
     "iopub.status.busy": "2022-05-29T20:56:48.111786Z",
     "iopub.status.idle": "2022-05-29T20:56:48.312126Z",
     "shell.execute_reply": "2022-05-29T20:56:48.311423Z"
    },
    "papermill": {
     "duration": 0.235131,
     "end_time": "2022-05-29T20:56:48.314030",
     "exception": false,
     "start_time": "2022-05-29T20:56:48.078899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_car_image(car_name):\n",
    "    return os.path.join(DATA_DIR,f\"{car_name}.jpg\")\n",
    "\n",
    "\n",
    "def car_annotations(car_name):\n",
    "    return os.path.join(DATA_DIR, f\"{car_name}.xml\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    To handle the data loading as different images may have different number\n",
    "    of objects and to handle varying size tensors as well.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "BOX_COLOR = (255, 0, 0)  # Red\n",
    "TEXT_COLOR = (255, 255, 255)  # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "    x_min, y_min, x_max,y_max=bbox\n",
    "\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "\n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        text=class_name,\n",
    "        org=(x_min, y_min - int(0.3 * text_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=0.35,\n",
    "        color=TEXT_COLOR,\n",
    "        lineType=cv2.LINE_AA,\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids, category_id_to_name):\n",
    "    img = image.copy()\n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        class_name = category_id_to_name[category_id]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def is_inside(big_box, small_box,epsilon=100):\n",
    "    \"\"\"\n",
    "    Checks if small_box is inside big_box wrt epsilon threshold\n",
    "\n",
    "    :param big_box:\n",
    "    :param small_box:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = big_box\n",
    "    x_min_s, y_min_s, x_max_s, y_max_s = small_box\n",
    "    if x_min_s > x_min - epsilon and x_max_s < x_max + epsilon and y_min_s > y_min - epsilon and y_max_s < y_max+ epsilon:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_bboxes_ids(batch_predictions,sample_id):\n",
    "    \"\"\"\n",
    "    return bboxes inside plate, and align according to xmin positions\n",
    "\n",
    "    :param predictions:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    PLID = CLASSES_IDS[CLASS_PLATE]\n",
    "    preds=batch_predictions[sample_id]\n",
    "    labels=preds['labels'].cpu().numpy()\n",
    "    bboxes=preds['boxes'].cpu().numpy()\n",
    "    idx_box_plate=np.where(labels==PLID)\n",
    "    if len(idx_box_plate[0])==0:\n",
    "        return []\n",
    "    else:\n",
    "\n",
    "        box_plate=bboxes[idx_box_plate[0],:].squeeze()\n",
    "    id_boxes=[]\n",
    "    for i in range(len(bboxes)):\n",
    "        if i == idx_box_plate[0]:\n",
    "            continue\n",
    "        box=bboxes[i,:].squeeze()\n",
    "        if is_inside(box_plate,box):\n",
    "            id_boxes.append(i)\n",
    "    id_boxes=sorted(id_boxes,key=lambda x:bboxes[x,0],reverse=False)##Sorted by x min\n",
    "    return id_boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c4d05",
   "metadata": {
    "papermill": {
     "duration": 0.031285,
     "end_time": "2022-05-29T20:56:48.376989",
     "exception": false,
     "start_time": "2022-05-29T20:56:48.345704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b12154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:48.440771Z",
     "iopub.status.busy": "2022-05-29T20:56:48.440575Z",
     "iopub.status.idle": "2022-05-29T20:56:51.643860Z",
     "shell.execute_reply": "2022-05-29T20:56:51.643141Z"
    },
    "papermill": {
     "duration": 3.237608,
     "end_time": "2022-05-29T20:56:51.645959",
     "exception": false,
     "start_time": "2022-05-29T20:56:48.408351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the dataset class\n",
    "import glob\n",
    "import os\n",
    "from enum import Enum\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import cv2.cv2\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "try :\n",
    "    from constants import DATASET_ROOT_DIR, CLASSES_IDS, CLASS_PLATE\n",
    "except ImportError:\n",
    "    \"\"\"\n",
    "    Can not work with notebooks\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "INPUT_SIZE = (600,600)\n",
    "CROP_RATIO=1.0\n",
    "\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    TRAIN = \"training\"\n",
    "    VALID = \"validation\"\n",
    "    TEST = \"testing\"\n",
    "class CarPlateDataset(Dataset):\n",
    "    def __init__(self, type: DatasetType = DatasetType.TRAIN):\n",
    "        self.type = type\n",
    "        self.dataset_dir = os.path.join(DATASET_ROOT_DIR, self.type.value)\n",
    "        self.tracks_dict = {}\n",
    "        self.tracks = []\n",
    "        self.transforms=A.Compose([\n",
    "            A.Resize(height=INPUT_SIZE[0], width=INPUT_SIZE[1], always_apply=True),\n",
    "            ToTensorV2(always_apply=True)\n",
    "        ],\n",
    "            bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels']),\n",
    "        )\n",
    "\n",
    "        self.read_all_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tracks)\n",
    "\n",
    "    def read_all_data(self):\n",
    "        \"\"\"\n",
    "        Real all data from the dataset\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for file in glob.glob(f'{self.dataset_dir}/**/*.txt', recursive=True):\n",
    "            track = os.path.basename(file).split(\".\")[0]\n",
    "            annotation_file = file\n",
    "            image_file = file.replace(\".txt\", \".png\")\n",
    "            self.tracks_dict[track] = (image_file, annotation_file)\n",
    "            self.tracks.append(track)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        track = self.tracks[idx]\n",
    "        image_file, annotation_file = self.tracks_dict[track]\n",
    "        with open(annotation_file, \"r\") as f :\n",
    "            annotations = f.readlines()\n",
    "        plate_id = annotations[6].split(\":\")[1].strip().replace(\"-\", \"\")\n",
    "\n",
    "        labels = [CLASSES_IDS[CLASS_PLATE]] + [CLASSES_IDS[c] for c in plate_id]\n",
    "        image=cv2.imread(image_file)\n",
    "        image=image/255.0\n",
    "        # Parsing annotations\n",
    "        bboxes = []\n",
    "        line_plate = annotations[7].split(\":\")[1].strip()\n",
    "        plate_bbox = [float(x) for x in line_plate.split(\" \")]\n",
    "        plate_bbox = [plate_bbox[0], plate_bbox[1], plate_bbox[0]+plate_bbox[2], plate_bbox[1]+plate_bbox[3]]\n",
    "        bboxes.append(plate_bbox)\n",
    "\n",
    "        for line in annotations[8:]:\n",
    "            content = line.split(\":\")[1].strip()\n",
    "            bbox = [int(x) for x in content.split(\" \")]\n",
    "            bbox = [bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]]\n",
    "            bboxes.append(bbox)\n",
    "\n",
    "        target=self.transforms(\n",
    "            image=image,\n",
    "            labels=np.array(labels),\n",
    "            bboxes=np.array(bboxes)\n",
    "\n",
    "        )\n",
    "        target={\"image\":torch.as_tensor(target[\"image\"],dtype=torch.float32),\"labels\":torch.as_tensor(target[\"labels\"],dtype=torch.int64),\n",
    "                \"boxes\":torch.as_tensor(target[\"bboxes\"],dtype=torch.float32),\n",
    "                \"image_id\":torch.as_tensor(idx,dtype=torch.float32)}\n",
    "        return target[\"image\"], target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2131aa",
   "metadata": {
    "papermill": {
     "duration": 0.031117,
     "end_time": "2022-05-29T20:56:51.709056",
     "exception": false,
     "start_time": "2022-05-29T20:56:51.677939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bfbb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:51.773044Z",
     "iopub.status.busy": "2022-05-29T20:56:51.772821Z",
     "iopub.status.idle": "2022-05-29T20:56:51.863425Z",
     "shell.execute_reply": "2022-05-29T20:56:51.862759Z"
    },
    "papermill": {
     "duration": 0.124864,
     "end_time": "2022-05-29T20:56:51.865240",
     "exception": false,
     "start_time": "2022-05-29T20:56:51.740376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch import nn\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
    "\n",
    "try:\n",
    "    from constants import NUM_CLASSES, ROOT_DIR, ALLOW_GPU\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "use_cuda = torch.cuda.is_available() and ALLOW_GPU\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "class ALPRNetwork(nn.Module):\n",
    "    def __init__(self, model_name=\"FasterRCNN\", reset=False, load_best=False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.reset = reset\n",
    "        self.load_best = load_best\n",
    "        self.setup_network()\n",
    "        self.setup_checkpoints()\n",
    "\n",
    "    # 1. Setup Network archi\n",
    "    def setup_network(self):\n",
    "        # self.backbone = torchvision.models.__dict__[\"resnet18\"](pretrained=True)\n",
    "        # self.backbone= nn.Sequential(  *list(self.backbone.children())[:-1])  ## Remove the last layer of resnet as it is a classificatoin layer\n",
    "\n",
    "        model_name = 'efficientnet-b7'\n",
    "        model = EfficientNet.from_pretrained(model_name)\n",
    "        conv_stem = torch.nn.Sequential(model._conv_stem)\n",
    "        bn = torch.nn.Sequential(model._bn0)\n",
    "        blocks = torch.nn.Sequential(*model._blocks)\n",
    "        conv_head = torch.nn.Sequential(model._conv_head)\n",
    "\n",
    "        # Freezing some layers\n",
    "        for p in conv_stem.parameters(): p.requires_grad = False\n",
    "        for child in list(blocks.children())[:-2]:\n",
    "            for p in child.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.backbone = torch.nn.Sequential(conv_stem, bn, blocks, conv_head)\n",
    "        self.backbone.out_channels = 2560\n",
    "\n",
    "        # Freezing some layers\n",
    "        anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                           aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "        roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "        self.model = FasterRCNN(self.backbone,\n",
    "                                num_classes=NUM_CLASSES,\n",
    "                                rpn_anchor_generator=anchor_generator,\n",
    "                                box_roi_pool=roi_pooler)\n",
    "\n",
    "    ##2. Model Saving/Loading\n",
    "    def load_state(self):\n",
    "        \"\"\"\n",
    "        Load model\n",
    "        :param self:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.load_best and os.path.exists(self.save_best_file):\n",
    "            logging.info(f\"Loading best model state : {self.save_file}\")\n",
    "            self.model.load_state_dict(torch.load(self.save_file, map_location=device))\n",
    "            return\n",
    "\n",
    "        if os.path.exists(self.save_file):\n",
    "            logging.info(f\"Loading model state : {self.save_file}\")\n",
    "            self.model.load_state_dict(torch.load(self.save_file, map_location=device))\n",
    "\n",
    "    def save_state(self, best=False):\n",
    "        if best:\n",
    "            torch.save(self.model.state_dict(), self.save_best_file)\n",
    "\n",
    "        torch.save(self.model.state_dict(), self.save_file)\n",
    "\n",
    "    ##3. Setupping directories for weights /logs ... etc\n",
    "    def setup_checkpoints(self):\n",
    "        \"\"\"\n",
    "        Checking and creating directories for weights storage\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        self.save_path = os.path.join(ROOT_DIR, 'logs', 'zoos')\n",
    "        self.model_dir = os.path.join(self.save_path, self.model_name)\n",
    "        self.save_file = os.path.join(self.model_dir, f\"{self.model_name}.pt\")\n",
    "        self.save_best_file = os.path.join(self.model_dir, f\"{self.model_name}_best.pt\")\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        elif not self.reset:\n",
    "            self.load_state()\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bf5e9",
   "metadata": {
    "papermill": {
     "duration": 0.031922,
     "end_time": "2022-05-29T20:56:51.928479",
     "exception": false,
     "start_time": "2022-05-29T20:56:51.896557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hamming metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b3606c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:51.994196Z",
     "iopub.status.busy": "2022-05-29T20:56:51.993826Z",
     "iopub.status.idle": "2022-05-29T20:56:51.999508Z",
     "shell.execute_reply": "2022-05-29T20:56:51.998827Z"
    },
    "papermill": {
     "duration": 0.040216,
     "end_time": "2022-05-29T20:56:52.001227",
     "exception": false,
     "start_time": "2022-05-29T20:56:51.961011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hamming_score(ref, pred):\n",
    "    \"\"\"\n",
    "    Calculates the Hamming distance between two strings.\n",
    "    \"\"\"\n",
    "    penalty = 0\n",
    "    if len(ref) != len(pred):\n",
    "        min_length=min(len(ref),len(pred))\n",
    "        max_length=max(len(ref),len(pred))\n",
    "\n",
    "        ref=ref[:min_length]\n",
    "        pred=pred[:min_length]\n",
    "        penalty=max_length-min_length\n",
    "\n",
    "    \n",
    "    assert len(ref) == len(pred)\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(ref, pred))+penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8f552f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:52.065888Z",
     "iopub.status.busy": "2022-05-29T20:56:52.065709Z",
     "iopub.status.idle": "2022-05-29T20:56:52.085103Z",
     "shell.execute_reply": "2022-05-29T20:56:52.084507Z"
    },
    "papermill": {
     "duration": 0.053182,
     "end_time": "2022-05-29T20:56:52.086704",
     "exception": false,
     "start_time": "2022-05-29T20:56:52.033522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch import nn\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
    "\n",
    "try:\n",
    "    from constants import NUM_CLASSES, ROOT_DIR\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "class ALPRNetwork(nn.Module):\n",
    "    def __init__(self, model_name=\"FasterRCNN\", reset=False, load_best=False):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.reset = reset\n",
    "        self.load_best = load_best\n",
    "        self.setup_checkpoints()\n",
    "        self.setup_network()\n",
    "        self.setup_checkpoints()\n",
    "\n",
    "    # 1. Setup Network archi\n",
    "    def setup_network(self):\n",
    "        # self.backbone = torchvision.models.__dict__[\"resnet18\"](pretrained=True)\n",
    "        # self.backbone= nn.Sequential(  *list(self.backbone.children())[:-1])  ## Remove the last layer of resnet as it is a classificatoin layer\n",
    "\n",
    "        model_name = 'efficientnet-b4'\n",
    "        model = EfficientNet.from_pretrained(model_name)\n",
    "        conv_stem = torch.nn.Sequential(model._conv_stem)\n",
    "        bn = torch.nn.Sequential(model._bn0)\n",
    "        blocks = torch.nn.Sequential(*model._blocks)\n",
    "        conv_head = torch.nn.Sequential(model._conv_head)\n",
    "\n",
    "        # Freezing some layers\n",
    "        for p in conv_stem.parameters(): p.requires_grad = False\n",
    "        for child in list(blocks.children())[:-2]:\n",
    "            for p in child.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.backbone = torch.nn.Sequential(conv_stem, bn, blocks, conv_head)\n",
    "        self.backbone.out_channels = 1792\n",
    "\n",
    "        # Freezing some layers\n",
    "        anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                           aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "        roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "        self.model = FasterRCNN(self.backbone,\n",
    "                                num_classes=NUM_CLASSES,\n",
    "                                rpn_anchor_generator=anchor_generator,\n",
    "                                box_roi_pool=roi_pooler)\n",
    "\n",
    "    ##2. Model Saving/Loading\n",
    "    def load_state(self):\n",
    "        \"\"\"\n",
    "        Load model\n",
    "        :param self:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.load_best and os.path.exists(self.save_best_file):\n",
    "            logging.info(f\"Loading best model state : {self.save_file}\")\n",
    "            self.model.load_state_dict(torch.load(self.save_file, map_location=device))\n",
    "            return\n",
    "\n",
    "        if os.path.exists(self.save_file):\n",
    "            logging.info(f\"Loading model state : {self.save_file}\")\n",
    "            self.model.load_state_dict(torch.load(self.save_file, map_location=device))\n",
    "\n",
    "    def save_state(self, best=False):\n",
    "        if best:\n",
    "            torch.save(self.model.state_dict(), self.save_best_file)\n",
    "\n",
    "        torch.save(self.model.state_dict(), self.save_file)\n",
    "\n",
    "    ##3. Setupping directories for weights /logs ... etc\n",
    "    def setup_checkpoints(self):\n",
    "        \"\"\"\n",
    "        Checking and creating directories for weights storage\n",
    "        @return:\n",
    "        \"\"\"\n",
    "        self.save_path = os.path.join(ROOT_DIR, 'logs', 'zoos')\n",
    "        self.model_dir = os.path.join(self.save_path, self.model_name)\n",
    "        self.save_file = os.path.join(self.model_dir, f\"{self.model_name}.pt\")\n",
    "        self.save_best_file = os.path.join(self.model_dir, f\"{self.model_name}_best.pt\")\n",
    "        if not os.path.exists(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        elif not self.reset:\n",
    "            self.load_state()\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        return self.model(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e354801",
   "metadata": {
    "papermill": {
     "duration": 0.030894,
     "end_time": "2022-05-29T20:56:52.148745",
     "exception": false,
     "start_time": "2022-05-29T20:56:52.117851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f790b7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:52.230919Z",
     "iopub.status.busy": "2022-05-29T20:56:52.230577Z",
     "iopub.status.idle": "2022-05-29T20:56:52.497059Z",
     "shell.execute_reply": "2022-05-29T20:56:52.496337Z"
    },
    "papermill": {
     "duration": 0.318913,
     "end_time": "2022-05-29T20:56:52.499509",
     "exception": false,
     "start_time": "2022-05-29T20:56:52.180596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import hamming_loss\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "try:\n",
    "    from utils import is_inside, extract_bboxes_ids\n",
    "    from constants import ROOT_DIR, CLASSES_IDS, CLASS_PLATE\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import tqdm\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, network, optimizer, nb_epochs, reset=False):\n",
    "        self.network = network\n",
    "        self.optimizer = optimizer\n",
    "        self.nb_epochs = nb_epochs\n",
    "\n",
    "        self.tb_dir = os.path.join(ROOT_DIR, 'logs', 'tensorboard', network.model_name)\n",
    "        self.info_file = os.path.join(self.tb_dir, 'info.json')\n",
    "        self.reset = reset\n",
    "        if os.path.exists(self.info_file) and not self.reset:\n",
    "            self.infos = json.load(open(self.info_file))\n",
    "\n",
    "            ##Load learning rate:\n",
    "\n",
    "        else:\n",
    "            self.infos = {'best_val_loss': float('inf'), 'epoch': 0, 'train_itr': 0,\n",
    "                          'lr': self.optimizer.param_groups[0]['lr'],\n",
    "\n",
    "                          }\n",
    "        self.summary_writer = SummaryWriter(self.tb_dir)\n",
    "\n",
    "    def fit(self, train_dataloader, valid_dataloader):\n",
    "        self.network.to(device)\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        logging.info('Training started on device : {}. lr={}'.format(device, self.optimizer.param_groups[0]['lr']))\n",
    "        train_itr = self.infos['train_itr']\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.infos['lr']\n",
    "\n",
    "        start_epoch = self.infos['epoch'] if self.infos['epoch'] else 0\n",
    "        self.nb_epochs = start_epoch + self.nb_epochs\n",
    "        for epoch in range(start_epoch, self.nb_epochs):\n",
    "            self.network.train()\n",
    "            loss, loss_cf = self.train_epoch_loop(train_dataloader, epoch, train_itr)\n",
    "            eval_loss = self.validate_loop(valid_dataloader, epoch)\n",
    "            # scheduler.step(loss)\n",
    "            train_itr = train_itr + len(train_dataloader)\n",
    "            best=False\n",
    "            if eval_loss < self.infos['best_val_loss']:\n",
    "                best=True\n",
    "                self.infos['best_val_loss'] = eval_loss\n",
    "            self.infos['epoch'] = epoch\n",
    "            self.infos['train_itr'] = train_itr\n",
    "            self.infos['lr'] = self.optimizer.param_groups[0]['lr']\n",
    "            json.dump(self.infos, open(self.info_file, 'w'))\n",
    "            logging.info(\n",
    "                'Epoch {}/{} : loss={:.4f} , loss_cf={:.4f} , eval_loss_hamming={:.4f} , lr={:.6f}'.format(epoch,\n",
    "                                                                                                           self.nb_epochs,\n",
    "                                                                                                           loss,\n",
    "                                                                                                           loss_cf,\n",
    "                                                                                                           eval_loss,\n",
    "                                                                                                           self.infos[\n",
    "                                                                                                               'lr']))\n",
    "            self.network.save_state(best=best)\n",
    "            \n",
    "    \n",
    "    def train_epoch_loop(self, dataloader, epoch, train_itr):\n",
    "        loss, loss_classification, loss_box_reg, loss_objectness = Averager(), Averager(), Averager(), Averager()\n",
    "        pbar = tqdm.tqdm(dataloader, desc='Training epoch {}/{}'.format(epoch, self.nb_epochs))\n",
    "        for batch in pbar:\n",
    "            train_itr += 1\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            images, targets = batch\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = self.network(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "            loss_cf = loss_dict['loss_classifier'].cpu().item()\n",
    "            loss.send(loss_value)\n",
    "            loss_classification.send(loss_cf)\n",
    "            loss_box_reg.send(loss_dict['loss_box_reg'].cpu().item())\n",
    "            loss_objectness.send(loss_dict['loss_objectness'].cpu().item())\n",
    "\n",
    "            self.summary_writer.add_scalar('Train/loss', loss_value, train_itr)\n",
    "            self.summary_writer.add_scalar('Train/loss_classification', loss_dict['loss_classifier'].cpu().item(),\n",
    "                                           train_itr)\n",
    "            self.summary_writer.add_scalar('Train/loss_box_reg', loss_dict['loss_box_reg'].cpu().item(), train_itr)\n",
    "            self.summary_writer.add_scalar('Train/loss_objectness', loss_dict['loss_objectness'].cpu().item(),\n",
    "                                           train_itr)\n",
    "            losses.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pbar.set_description(\n",
    "                'Training epoch {}/{}. Loss :{}, loss_classifier :{}'.format(epoch, self.nb_epochs, loss_value, loss_cf))\n",
    "\n",
    "        epoch_loss = loss.value\n",
    "        epoch_loss_classification = loss_classification.value\n",
    "        epoch_loss_box_reg = loss_box_reg.value\n",
    "        epoch_loss_objectness = loss_objectness.value\n",
    "        self.summary_writer.add_scalar('Train/epoch_loss', epoch_loss, epoch)\n",
    "        self.summary_writer.add_scalar('Train/epoch_loss_classification', epoch_loss_classification, epoch)\n",
    "        self.summary_writer.add_scalar('Train/epoch_loss_box_reg', epoch_loss_box_reg, epoch)\n",
    "        self.summary_writer.add_scalar('Train/epoch_loss_objectness', epoch_loss_objectness, epoch)\n",
    "        return epoch_loss, epoch_loss_classification\n",
    "\n",
    "    def validate_loop(self, valid_dataloader, epoch):\n",
    "        # loss,loss_classification,loss_box_reg,loss_objectness=Averager(),Averager(),Averager(),Averager()\n",
    "        self.network.eval()\n",
    "        with torch.no_grad():\n",
    "            hammings = Averager()\n",
    "            pbar=tqdm.tqdm(valid_dataloader, desc='Validating epoch {}'.format(epoch))\n",
    "            for batch in pbar:\n",
    "                images, targets = batch\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                predictions = self.network(images)\n",
    "                for sample_id in range(len(predictions)):\n",
    "                    bboxes_ids = extract_bboxes_ids(predictions, sample_id)\n",
    "                    pred_all_label = predictions[sample_id]['labels'].cpu().numpy()\n",
    "                    pred_labels = [] + [int(pred_all_label[id]) for id in bboxes_ids]\n",
    "                    true_labels = targets[sample_id]['labels'].cpu().numpy()[1:]  # Remove plate prediciotns\n",
    "                    h_loss=hamming_score(pred_labels, true_labels)\n",
    "                    hammings.send(h_loss)\n",
    "                    pbar.set_description('Validating epoch {}. Hamming loss : {}'.format(epoch,h_loss))\n",
    "                    \n",
    "            self.summary_writer.add_scalar('Valid/Hamming LP Loss', hammings.value, epoch)\n",
    "            return hammings.value\n",
    "\n",
    "            # labels=[t['labels'].cpu().numpy() for t in targets]\n",
    "\n",
    "            #\n",
    "            #\n",
    "            #\n",
    "            #\n",
    "            #\n",
    "            # loss_dict=self.network(images,targets)\n",
    "            # losses = sum(loss for loss in loss_dict.values())\n",
    "            # loss_value = losses.item()\n",
    "            # loss.send(loss_value)\n",
    "            # loss_classification.send(loss_dict['loss_classifier'].cpu().item())\n",
    "            # loss_box_reg.send(loss_dict['loss_box_reg'].cpu().item())\n",
    "            # loss_objectness.send(loss_dict['loss_objectness'].cpu().item())\n",
    "            #\n",
    "            # self.summary_writer.add_scalar('Valid/loss',loss_value,epoch)\n",
    "            # self.summary_writer.add_scalar('Valid/loss_classification',loss_dict['loss_classifier'].cpu().item(),epoch)\n",
    "            # self.summary_writer.add_scalar('Valid/loss_box_reg',loss_dict['loss_box_reg'].cpu().item(),epoch)\n",
    "            # self.summary_writer.add_scalar('Valid/loss_objectness',loss_dict['loss_objectness'].cpu().item(),epoch)\n",
    "        # epoch_loss=loss.value\n",
    "        # epoch_loss_classification=loss_classification.value\n",
    "        # epoch_loss_box_reg=loss_box_reg.value\n",
    "        # epoch_loss_objectness=loss_objectness.value\n",
    "        # self.summary_writer.add_scalar('Valid/epoch_loss',epoch_loss,epoch)\n",
    "        # self.summary_writer.add_scalar('Valid/epoch_loss_classification',epoch_loss_classification,epoch)\n",
    "        # self.summary_writer.add_scalar('Valid/epoch_loss_box_reg',epoch_loss_box_reg,epoch)\n",
    "        # self.summary_writer.add_scalar('Valid/epoch_loss_objectness',epoch_loss_objectness,epoch)\n",
    "        # return epoch_loss,epoch_loss_classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69550237",
   "metadata": {
    "papermill": {
     "duration": 0.050741,
     "end_time": "2022-05-29T20:56:52.601874",
     "exception": false,
     "start_time": "2022-05-29T20:56:52.551133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4539f1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:52.705435Z",
     "iopub.status.busy": "2022-05-29T20:56:52.705197Z",
     "iopub.status.idle": "2022-05-29T20:56:59.261263Z",
     "shell.execute_reply": "2022-05-29T20:56:59.260444Z"
    },
    "papermill": {
     "duration": 6.610222,
     "end_time": "2022-05-29T20:56:59.263297",
     "exception": false,
     "start_time": "2022-05-29T20:56:52.653075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-49aeed9cc55323c2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-49aeed9cc55323c2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %tensorflow_version 2.x\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d1add5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T20:56:59.328349Z",
     "iopub.status.busy": "2022-05-29T20:56:59.327692Z",
     "iopub.status.idle": "2022-05-29T21:06:30.871603Z",
     "shell.execute_reply": "2022-05-29T21:06:30.870658Z"
    },
    "papermill": {
     "duration": 571.578747,
     "end_time": "2022-05-29T21:06:30.873874",
     "exception": false,
     "start_time": "2022-05-29T20:56:59.295127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb0d591005a40d585a926019472b05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/74.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "2022-05-29 20:57:11,188 - root - INFO - Training started on device : cuda. lr=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0/1. Loss :0.11803209781646729, loss_classifier :0.041821811348199844: 100%|██████████| 1800/1800 [07:39<00:00,  3.92it/s]\n",
      "Validating epoch 0. Hamming loss : 7: 100%|██████████| 900/900 [01:37<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-29 21:06:27,323 - root - INFO - Epoch 0/1 : loss=0.1582 , loss_cf=0.0662 , eval_loss_hamming=7.0000 , lr=0.000010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "reset=True\n",
    "network=ALPRNetwork(reset=reset)\n",
    "optimizer=Adam(lr=1e-5, params=[param for param in network.parameters() if param.requires_grad])\n",
    "trainer=Trainer(network, optimizer,nb_epochs=1,reset=reset)\n",
    "train_dataset,valid_dataset=CarPlateDataset(type=DatasetType.TRAIN),CarPlateDataset(type=DatasetType.VALID)\n",
    "train_dataloader,valid_dataloader=DataLoader(train_dataset,batch_size=1,shuffle=True,collate_fn=collate_fn,num_workers=2),\\\n",
    "                                  DataLoader(valid_dataset,batch_size=1,shuffle=True,collate_fn=collate_fn,num_workers=2)\n",
    "trainer.fit(train_dataloader,valid_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2658aff",
   "metadata": {
    "papermill": {
     "duration": 1.784241,
     "end_time": "2022-05-29T21:06:34.262209",
     "exception": false,
     "start_time": "2022-05-29T21:06:32.477968",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 640.129878,
   "end_time": "2022-05-29T21:06:38.962782",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-29T20:55:58.832904",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d1d0b512b4c40eab7bfe466803d326c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3529ec4d4ae64809af3adbf799ea7687": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "41e988d0df3b4dc989ef4b8ce133a1e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "471aec31efdb4ff69c648e2a530b3f33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bb0d591005a40d585a926019472b05a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4bfe73e11e534ebc859d1e0c012358e9",
        "IPY_MODEL_e1b1dc9df4e14052a70f48716baf55e0",
        "IPY_MODEL_a4bf439156dd4f62939ebeeadd5f60d3"
       ],
       "layout": "IPY_MODEL_6b864cfcbb01472eb3e8f8ad478b33b6"
      }
     },
     "4bfe73e11e534ebc859d1e0c012358e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1d1d0b512b4c40eab7bfe466803d326c",
       "placeholder": "​",
       "style": "IPY_MODEL_3529ec4d4ae64809af3adbf799ea7687",
       "value": "100%"
      }
     },
     "6b864cfcbb01472eb3e8f8ad478b33b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72370a961d344961beb41f9af1eaca7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "944db64c978a4cfab471bb19c4b3054a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a4bf439156dd4f62939ebeeadd5f60d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_72370a961d344961beb41f9af1eaca7d",
       "placeholder": "​",
       "style": "IPY_MODEL_41e988d0df3b4dc989ef4b8ce133a1e6",
       "value": " 74.4M/74.4M [00:01&lt;00:00, 48.0MB/s]"
      }
     },
     "e1b1dc9df4e14052a70f48716baf55e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_471aec31efdb4ff69c648e2a530b3f33",
       "max": 77999237.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_944db64c978a4cfab471bb19c4b3054a",
       "value": 77999237.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
